{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample_sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn==0.20.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "\n",
    "# Renaming the 'EmployeeNumber' column to 'id'\n",
    "original_data = original_data.rename(columns={\"EmployeeNumber\": \"id\"})\n",
    "\n",
    "# Converting 'Attrition' values from 'Yes' to integer 1 and other values to integer 0\n",
    "original_data[\"Attrition\"] = (original_data[\"Attrition\"] == \"Yes\").astype(int)\n",
    "\n",
    "# rearrange columns so that they are in the same order as in train\n",
    "original_data = original_data[train.columns.tolist()]\n",
    "\n",
    "original_data[\"source\"] = \"original\"\n",
    "train[\"source\"] = \"synthetic\"\n",
    "test[\"source\"] = \"synthetic\"\n",
    "\n",
    "# combining the datasets\n",
    "train = pd.concat([train, original_data])\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
       "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
       "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
       "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
       "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager', 'Attrition', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "features.remove(\"id\")\n",
    "features.remove(\"Attrition\")\n",
    "\n",
    "target = \"Attrition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns  # array of column names to encode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # not relevant here\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        \"\"\"\n",
    "        output = X.copy()\n",
    "\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname, col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'Over18',\n",
       " 'OverTime',\n",
       " 'source']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_strings_as_values = list((train.dtypes[train.dtypes == \"object\"]).index)\n",
    "columns_with_strings_as_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = MultiColumnLabelEncoder(columns=columns_with_strings_as_values)\n",
    "train = label_encoder.fit_transform(train)\n",
    "test = label_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1152\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1150\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1155\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1150\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 393, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2832, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138771 -> initscore=-1.825534\n",
      "[LightGBM] [Info] Start training from score -1.825534\n",
      "[LightGBM] [Info] Number of positive: 394, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1152\n",
      "[LightGBM] [Info] Number of data points in the train set: 2833, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.139075 -> initscore=-1.822992\n",
      "[LightGBM] [Info] Start training from score -1.822992\n",
      "[LightGBM] [Info] Number of positive: 394, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2833, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.139075 -> initscore=-1.822992\n",
      "[LightGBM] [Info] Start training from score -1.822992\n",
      "[LightGBM] [Info] Number of positive: 394, number of negative: 2439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1151\n",
      "[LightGBM] [Info] Number of data points in the train set: 2833, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.139075 -> initscore=-1.822992\n",
      "[LightGBM] [Info] Start training from score -1.822992\n",
      "Mean score across all folds: 0.8338670104460029\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "scores = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for train_index, val_index in kf.split(train, y=train[\"Attrition\"]):\n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=150,\n",
    "        categorical_feature=[1, 3, 6, 9, 13, 15, 19, 20, 33],\n",
    "        metric=\"auc\",\n",
    "    )\n",
    "    clf.fit(X_train.values, y_train, eval_set=[(X_val, y_val)])\n",
    "    preds = clf.predict_proba(X_val.values)\n",
    "\n",
    "    clfs.append(clf)\n",
    "    scores.append(roc_auc_score(y_val, preds[:, 1]))\n",
    "\n",
    "print(\"Mean score across all folds:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonthlyIncome 0.09866666666666667\n",
      "DailyRate 0.08177777777777778\n",
      "MonthlyRate 0.0791111111111111\n",
      "HourlyRate 0.074\n",
      "Age 0.06844444444444445\n",
      "DistanceFromHome 0.06333333333333334\n",
      "PercentSalaryHike 0.03977777777777778\n",
      "YearsAtCompany 0.034666666666666665\n",
      "RelationshipSatisfaction 0.03311111111111111\n",
      "EnvironmentSatisfaction 0.03244444444444444\n",
      "TotalWorkingYears 0.03222222222222222\n",
      "NumCompaniesWorked 0.03088888888888889\n",
      "TrainingTimesLastYear 0.029777777777777778\n",
      "JobSatisfaction 0.029111111111111112\n",
      "JobInvolvement 0.028444444444444446\n",
      "YearsSinceLastPromotion 0.026\n",
      "YearsWithCurrManager 0.026\n",
      "OverTime 0.025777777777777778\n",
      "BusinessTravel 0.023777777777777776\n",
      "StockOptionLevel 0.021333333333333333\n",
      "YearsInCurrentRole 0.021333333333333333\n",
      "WorkLifeBalance 0.01911111111111111\n",
      "Education 0.014222222222222223\n",
      "JobRole 0.012222222222222223\n",
      "MaritalStatus 0.011777777777777778\n",
      "source 0.011777777777777778\n",
      "Department 0.011111111111111112\n",
      "Gender 0.010444444444444444\n",
      "JobLevel 0.004888888888888889\n",
      "EducationField 0.0044444444444444444\n",
      "EmployeeCount 0.0\n",
      "Over18 0.0\n",
      "PerformanceRating 0.0\n",
      "StandardHours 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in clf.feature_importances_.argsort()[::-1]:\n",
    "    print(features[i], clf.feature_importances_[i]/clf.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-demo-idFOCadX-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
